{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import socket\n",
    "import struct\n",
    "import pennylane as qml\n",
    "import base64\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                            ExtraTreesClassifier, GradientBoostingClassifier)\n",
    "from lightgbm import LGBMClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"All.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()[df.isnull().sum() > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First drop the NumberRate_Extension column\n",
    "df = df.drop('NumberRate_Extension', axis=1)\n",
    "\n",
    "# Then drop rows with missing values in remaining columns\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df.drop(columns=\"URL_Type_obf_Type\")\n",
    "y = df['URL_Type_obf_Type']\n",
    "# Create encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform y\n",
    "y = le.fit_transform(y)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# First handle high correlations\n",
    "correlation_matrix = X.corr()\n",
    "high_corr_features = set()  # Keep track of features to drop\n",
    "\n",
    "# Find features with correlations > 0.8\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "            # Keep feature with lower mean correlation with other features\n",
    "            feat1, feat2 = correlation_matrix.columns[i], correlation_matrix.columns[j]\n",
    "            corr1 = correlation_matrix[feat1].abs().mean()\n",
    "            corr2 = correlation_matrix[feat2].abs().mean()\n",
    "            high_corr_features.add(feat1 if corr1 > corr2 else feat2)\n",
    "\n",
    "# Drop highly correlated features\n",
    "X_cleaned = X.drop(columns=list(high_corr_features))\n",
    "print(f\"Dropped {len(high_corr_features)} features due to high correlation\")\n",
    "\n",
    "# Now handle VIF\n",
    "def calculate_vif(data):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = data.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(data.values, i) for i in range(data.shape[1])]\n",
    "    vif_data[\"VIF\"] = vif_data[\"VIF\"].replace([np.inf], 1e10)\n",
    "    return vif_data.sort_values('VIF', ascending=False)\n",
    "\n",
    "# Iteratively remove high VIF features\n",
    "while True:\n",
    "    vif_data = calculate_vif(X_cleaned)\n",
    "    if vif_data['VIF'].max() <= 10:\n",
    "        break\n",
    "    worst_feature = vif_data.iloc[0]['Feature']\n",
    "    X_cleaned = X_cleaned.drop(worst_feature, axis=1)\n",
    "    print(f\"Dropped {worst_feature} with VIF: {vif_data.iloc[0]['VIF']:.2f}\")\n",
    "\n",
    "print(f\"\\nOriginal shape: {X.shape}\")\n",
    "print(f\"Final shape: {X_cleaned.shape}\")\n",
    "print(f\"\\nRemaining features:\\n{X_cleaned.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pennylane as qml\n",
    "# n_features = X.shape[1]\n",
    "# N = int(np.ceil(np.log2(n_features)))\n",
    "# wires = range(N)\n",
    "# dev = qml.device('default.qubit', wires)    \n",
    "\n",
    "# @qml.qnode(dev)\n",
    "# def circuit(f=None):\n",
    "#     qml.AmplitudeEmbedding(f, wires=wires,pad_with=0,normalize=True)\n",
    "#     return qml.state()\n",
    "# X_norm = X.values\n",
    "# X_quantum = circuit(X_norm)\n",
    "# X_real = np.real(np.array(X_quantum))\n",
    "# # Create column names based on index\n",
    "# column_names = [f'feature_{i}' for i in range(X_real.shape[1])]\n",
    "# X_real = pd.DataFrame(X_real, columns=column_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "N = X.shape[1]\n",
    "wires = range(N)\n",
    "dev = qml.device(\"default.qubit\", wires)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(val_list):\n",
    "    qml.AngleEmbedding(val_list, wires, rotation=\"Y\")\n",
    "    return [qml.expval(qml.PauliZ(w)) for w in wires]\n",
    "\n",
    "# Function to process DataFrame through quantum circuit\n",
    "def quantum_transform(df):\n",
    "    # Convert DataFrame to numpy array\n",
    "    values = df.values\n",
    "    values = values.reshape(values.shape[0], -1)\n",
    "    # Process each row through quantum circuit\n",
    "    quantum_features = np.array([circuit(row) for row in values])\n",
    "    # Remove tensor properties and convert to regular numpy array\n",
    "    quantum_features = np.array(quantum_features).astype(float)\n",
    "    return quantum_features\n",
    "# Transform your data\n",
    "X_real = quantum_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantum_cols = [f'quantum_state_{i}' for i in range(len(X_real[0]))]\n",
    "X_real = pd.DataFrame(X_real, columns=quantum_cols)\n",
    "X_real.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use this balanced data for training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_real, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = XGBClassifier(n_estimators=100, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# CatBoost\n",
    "# cat_model = CatBoostClassifier(n_estimators=100, random_state=42, verbose=False)\n",
    "# cat_model.fit(X_train, y_train)\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Print accuracy\n",
    "# print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# # Print detailed classification report\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Create confusion matrix visualization\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.show()\n",
    "\n",
    "# # Feature importance\n",
    "# feature_importance = pd.DataFrame({\n",
    "#     'feature': X.columns,\n",
    "#     'importance': rf_model.feature_importances_\n",
    "# }).sort_values('importance', ascending=False)\n",
    "\n",
    "# print(\"\\nFeature Importance:\")\n",
    "# print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Create a dictionary of all models\n",
    "models = {\n",
    "    \"SVM (Linear)\": SVC(kernel=\"linear\", random_state=42),\n",
    "    \"SVM (Poly)\": SVC(kernel=\"poly\", random_state=42),\n",
    "    \"SVM (RBF)\": SVC(kernel=\"rbf\", random_state=42),\n",
    "    \"SVM (Sigmoid)\": SVC(kernel=\"sigmoid\", random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Loop through each model for evaluation\n",
    "for name, model in models.items():\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Accuracy\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, predictions):.4f}\")\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(confusion_matrix(y_test, predictions), annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    # Feature Importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_real.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature Importance:\")\n",
    "    print(feature_importance)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env_126",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
