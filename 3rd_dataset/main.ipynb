{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                            ExtraTreesClassifier, GradientBoostingClassifier)\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"Spam_BestFirst.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "if df['class'].dtype not in ['int64', 'float64']:\n",
    "    le = LabelEncoder()\n",
    "    df['class'] = le.fit_transform(df['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()[df.isnull().sum() > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=\"class\")\n",
    "y = df['class']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pennylane as qml\n",
    "# n_features = X.shape[1]\n",
    "# N = int(np.ceil(np.log2(n_features)))\n",
    "# wires = range(N)\n",
    "# dev = qml.device('default.qubit', wires)    \n",
    "\n",
    "# @qml.qnode(dev)\n",
    "# def circuit(f=None):\n",
    "#     qml.AmplitudeEmbedding(f, wires=wires,pad_with=0,normalize=True)\n",
    "#     return qml.state()\n",
    "# X_norm = X.values\n",
    "# X_quantum = circuit(X_norm)\n",
    "# X_real = np.real(np.array(X_quantum))\n",
    "# # Create column names based on index\n",
    "# column_names = [f'feature_{i}' for i in range(X_real.shape[1])]\n",
    "# X_real = pd.DataFrame(X_real, columns=column_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "N = X.shape[1]\n",
    "wires = range(N)\n",
    "dev = qml.device(\"default.qubit\", wires)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit(data):\n",
    "    scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
    "    data = scaler.fit_transform(data.reshape(-1,1))\n",
    "    data = data.reshape(-1)\n",
    "    qml.AngleEmbedding(data, wires, rotation=\"Y\")\n",
    "    return [qml.expval(qml.PauliZ(w)) for w in wires]\n",
    "\n",
    "# Function to process DataFrame through quantum circuit\n",
    "def quantum_transform(df):\n",
    "    # Convert DataFrame to numpy array\n",
    "    values = df.values\n",
    "    # Process each row through quantum circuit\n",
    "    quantum_features = np.array([circuit(row) for row in values])\n",
    "    # Remove tensor properties and convert to regular numpy array\n",
    "    quantum_features = np.array(quantum_features).astype(float)\n",
    "    return quantum_features\n",
    "# Transform your data\n",
    "X_real = quantum_transform(X)\n",
    "quantum_cols = [f'quantum_state_{i}' for i in range(len(X_real[0]))]\n",
    "X_real = pd.DataFrame(X_real, columns=quantum_cols)\n",
    "X_real.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use this balanced data for training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Create a dictionary of models to evaluate\n",
    "models = {\n",
    "    \"SVM (Linear)\": SVC(kernel=\"linear\", random_state=42),\n",
    "    \"SVM (Poly)\": SVC(kernel=\"poly\", random_state=42),\n",
    "    \"SVM (RBF)\": SVC(kernel=\"rbf\", random_state=42),\n",
    "    \"SVM (Sigmoid)\": SVC(kernel=\"sigmoid\", random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Function to calculate metrics\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    start_time = time.time()  # Track model fitting time\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "\n",
    "    # Get performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "    cohen_kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    \n",
    "    # Running time\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    \n",
    "    # Detailed classification report\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    # Return all metrics\n",
    "    return {\n",
    "        \"Model\": model.__class__.__name__,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"Cohen's Kappa\": cohen_kappa,\n",
    "        \"Running Time (s)\": runtime,\n",
    "    }\n",
    "\n",
    "# Evaluating all models and storing results\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Evaluating model: {name}\")\n",
    "    result = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "    results.append(result)\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('results/spam_bestfirst_ang_norm.csv', index=False)\n",
    "\n",
    "# Display all the results\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env_126",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
